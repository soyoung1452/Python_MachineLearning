{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f9fe2b",
   "metadata": {},
   "source": [
    "### SPIMI (Single-Pass In-Memory Indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2ca0e",
   "metadata": {},
   "source": [
    "* 알고리즘은 단일 패스에서 메모리 내에서 인덱스를 구축하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bf0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 토큰화 라이브러리\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16f8c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sypar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811119e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41488fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 리스트를 입력으로 받고, 단어별로 역인덱스를 생성하여 반환\n",
    "def spimi_invert(tokenized_docs):\n",
    "    index = {}\n",
    "    doc_id = 0\n",
    "    \n",
    "    for doc in tokenized_docs:\n",
    "        for term in doc:\n",
    "            if term not in index:\n",
    "                index[term] = []\n",
    "            if doc_id not in index[term]:\n",
    "                index[term].append(doc_id)\n",
    "                \n",
    "        doc_id += 1\n",
    "    \n",
    "    return index\n",
    "\n",
    "# 핵심: index 딕셔너리를 사용하여 각 단어의 포스팅 리스트를 유지하는 것\n",
    "# 문서를 한 번 스캔하면서 각 단어를 처리하고\n",
    "# 해당 단어가 인덱스에 없으면 새로운 엔트리를 생성하고 포스팅 리스트에 문서ID를 추가\n",
    "# 이미 인덱스에 있는 단어인 경우에는 중복된 문서ID가 없도록 체크한 후 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc034554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 문장\n",
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cee1f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'the', 'first', 'document', '.'],\n",
       " ['this', 'document', 'is', 'the', 'second', 'document', '.'],\n",
       " ['and', 'this', 'is', 'the', 'third', 'one', '.'],\n",
       " ['is', 'this', 'the', 'first', 'document', '?']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 토큰화\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
    "tokenized_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ae2c599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': [0, 1, 2, 3],\n",
       " 'is': [0, 1, 2, 3],\n",
       " 'the': [0, 1, 2, 3],\n",
       " 'first': [0, 3],\n",
       " 'document': [0, 1, 3],\n",
       " '.': [0, 1, 2],\n",
       " 'second': [1],\n",
       " 'and': [2],\n",
       " 'third': [2],\n",
       " 'one': [2],\n",
       " '?': [3]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPIMI 인덱싱 수행\n",
    "index = spimi_invert(tokenized_docs)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c5cf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this: [0, 1, 2, 3]\n",
      "is: [0, 1, 2, 3]\n",
      "the: [0, 1, 2, 3]\n",
      "first: [0, 3]\n",
      "document: [0, 1, 3]\n",
      ".: [0, 1, 2]\n",
      "second: [1]\n",
      "and: [2]\n",
      "third: [2]\n",
      "one: [2]\n",
      "?: [3]\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "for term, postings in index.items():\n",
    "    print(f\"{term}: {postings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a952b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77d08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5b9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
